{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model IO - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key loading\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with open('../openai_api_key.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "    \n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Connection & Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Cultural Homogenization: With the increase in global trade and communication, there has been a merging of cultures, resulting in a loss of distinct cultural identities. This is especially seen in the spread of Western culture and consumerism, which has led to a homogenization of cultures around the world.\\n\\n2. Cultural Diversity: On the other hand, globalization has also led to the celebration and preservation of diverse cultures. With increased travel and exposure to different cultures, people have become more appreciative and curious about other ways of life, leading to a greater acceptance and celebration of cultural diversity.\\n\\n3. Cultural Exchange: Globalization has also facilitated the exchange of ideas, beliefs, and practices between different cultures. This has led to the adoption of certain elements of one culture by another, resulting in a fusion of cultures and the emergence of new cultural practices.\\n\\n4. Cultural Conflicts: As cultures come into contact with each other, there is also a potential for conflicts to arise. This can be seen in the clash of values and beliefs between different cultures, leading to tensions and misunderstandings.\\n\\n5. Preservation of Traditional Cultures: Globalization has also brought attention to the need to preserve traditional cultures and indigenous ways of life. This has led to efforts to protect and promote traditional practices'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single prompt\n",
    "\n",
    "prompt = \"The impact of the globalization on diverse cultures can be explained as:\"\n",
    "\n",
    "response = llm(prompt=prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cultural Homogenization: With the increase in global trade and communication, there has been a merging of cultures, resulting in a loss of distinct cultural identities. This is especially seen in the spread of Western culture and consumerism, which has led to a homogenization of cultures around the world.\n",
      "\n",
      "2. Cultural Diversity: On the other hand, globalization has also led to the celebration and preservation of diverse cultures. With increased travel and exposure to different cultures, people have become more appreciative and curious about other ways of life, leading to a greater acceptance and celebration of cultural diversity.\n",
      "\n",
      "3. Cultural Exchange: Globalization has also facilitated the exchange of ideas, beliefs, and practices between different cultures. This has led to the adoption of certain elements of one culture by another, resulting in a fusion of cultures and the emergence of new cultural practices.\n",
      "\n",
      "4. Cultural Conflicts: As cultures come into contact with each other, there is also a potential for conflicts to arise. This can be seen in the clash of values and beliefs between different cultures, leading to tensions and misunderstandings.\n",
      "\n",
      "5. Preservation of Traditional Cultures: Globalization has also brought attention to the need to preserve traditional cultures and indigenous ways of life. This has led to efforts to protect and promote traditional practices\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=\"\\n\\n1. Loss of Cultural Identity: As different cultures come in contact with each other, there is a fear of losing one's own cultural identity. This can be seen in the adoption of western lifestyles and values by people in non-western cultures.\\n\\n2. Homogenization of Culture: With the spread of global media and brands, there is a tendency towards a homogenization of culture. This means that diverse cultures are becoming more similar, leading to a loss of unique cultural practices and traditions.\\n\\n3. Cultural Appropriation: Globalization has also led to the appropriation of elements of one culture by another. This can lead to the exploitation and misrepresentation of these cultural elements, causing harm to the original culture.\\n\\n4. Cultural Clashes: When different cultures come in contact, there is a potential for clashes and conflicts. This can be seen in issues such as cultural imperialism, where dominant cultures impose their values and beliefs on others.\\n\\n5. Cultural Exchange and Fusion: Globalization has also led to an increase in cultural exchange and fusion. This can be seen in the rise of fusion cuisine, music, and fashion, where elements from different cultures are combined to create something new.\\n\\n6. Preservation of Traditional Culture: On the other hand, globalization has also provided a platform for the\", generation_info={'finish_reason': 'length', 'logprobs': None})], [Generation(text='\\n\\n1. Providing habitats: Ecosystems provide a variety of habitats, including forests, grasslands, wetlands, and oceans, which are home to a diverse range of species. These habitats provide shelter, food, and breeding grounds for different organisms, thus supporting their survival.\\n\\n2. Ensuring food availability: Ecosystems play a crucial role in maintaining the food web and ensuring that all species have access to food. Each species in an ecosystem depends on others for food, and a loss of one species can disrupt the entire food web, leading to a decline in biodiversity.\\n\\n3. Nutrient cycling: Ecosystems also play a vital role in nutrient cycling. The flow of nutrients between living organisms and the environment is essential for the growth and survival of all species. A diverse range of species is necessary to ensure efficient nutrient cycling, which supports the growth and survival of different organisms.\\n\\n4. Pollination: Many plants rely on pollinators such as bees, butterflies, and birds for reproduction. Ecosystems provide a suitable environment for these pollinators to thrive, ensuring the pollination of various plant species. This process is crucial for maintaining the genetic diversity of plants.\\n\\n5. Pest control: Biodiverse ecosystems are more resilient to pest outbreaks as different species act', generation_info={'finish_reason': 'length', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 21, 'completion_tokens': 512, 'total_tokens': 533}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=[RunInfo(run_id=UUID('16dca460-9666-48a7-83a1-9b2b62119a10')), RunInfo(run_id=UUID('640dda53-8fe4-41a1-afae-6f6652c2256d'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple prompts\n",
    "\n",
    "prompts = [\n",
    "    \"The impact of the globalization on diverse cultures can be explained as:\",\n",
    "    \"Ecosystems maintain biodiversity as follows:\"\n",
    "]\n",
    "\n",
    "response = llm.generate(prompts=prompts)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Generation(text=\"\\n\\n1. Loss of Cultural Identity: As different cultures come in contact with each other, there is a fear of losing one's own cultural identity. This can be seen in the adoption of western lifestyles and values by people in non-western cultures.\\n\\n2. Homogenization of Culture: With the spread of global media and brands, there is a tendency towards a homogenization of culture. This means that diverse cultures are becoming more similar, leading to a loss of unique cultural practices and traditions.\\n\\n3. Cultural Appropriation: Globalization has also led to the appropriation of elements of one culture by another. This can lead to the exploitation and misrepresentation of these cultural elements, causing harm to the original culture.\\n\\n4. Cultural Clashes: When different cultures come in contact, there is a potential for clashes and conflicts. This can be seen in issues such as cultural imperialism, where dominant cultures impose their values and beliefs on others.\\n\\n5. Cultural Exchange and Fusion: Globalization has also led to an increase in cultural exchange and fusion. This can be seen in the rise of fusion cuisine, music, and fashion, where elements from different cultures are combined to create something new.\\n\\n6. Preservation of Traditional Culture: On the other hand, globalization has also provided a platform for the\", generation_info={'finish_reason': 'length', 'logprobs': None})],\n",
       " [Generation(text='\\n\\n1. Providing habitats: Ecosystems provide a variety of habitats, including forests, grasslands, wetlands, and oceans, which are home to a diverse range of species. These habitats provide shelter, food, and breeding grounds for different organisms, thus supporting their survival.\\n\\n2. Ensuring food availability: Ecosystems play a crucial role in maintaining the food web and ensuring that all species have access to food. Each species in an ecosystem depends on others for food, and a loss of one species can disrupt the entire food web, leading to a decline in biodiversity.\\n\\n3. Nutrient cycling: Ecosystems also play a vital role in nutrient cycling. The flow of nutrients between living organisms and the environment is essential for the growth and survival of all species. A diverse range of species is necessary to ensure efficient nutrient cycling, which supports the growth and survival of different organisms.\\n\\n4. Pollination: Many plants rely on pollinators such as bees, butterflies, and birds for reproduction. Ecosystems provide a suitable environment for these pollinators to thrive, ensuring the pollination of various plant species. This process is crucial for maintaining the genetic diversity of plants.\\n\\n5. Pest control: Biodiverse ecosystems are more resilient to pest outbreaks as different species act', generation_info={'finish_reason': 'length', 'logprobs': None})]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Loss of Cultural Identity: As different cultures come in contact with each other, there is a fear of losing one's own cultural identity. This can be seen in the adoption of western lifestyles and values by people in non-western cultures.\n",
      "\n",
      "2. Homogenization of Culture: With the spread of global media and brands, there is a tendency towards a homogenization of culture. This means that diverse cultures are becoming more similar, leading to a loss of unique cultural practices and traditions.\n",
      "\n",
      "3. Cultural Appropriation: Globalization has also led to the appropriation of elements of one culture by another. This can lead to the exploitation and misrepresentation of these cultural elements, causing harm to the original culture.\n",
      "\n",
      "4. Cultural Clashes: When different cultures come in contact, there is a potential for clashes and conflicts. This can be seen in issues such as cultural imperialism, where dominant cultures impose their values and beliefs on others.\n",
      "\n",
      "5. Cultural Exchange and Fusion: Globalization has also led to an increase in cultural exchange and fusion. This can be seen in the rise of fusion cuisine, music, and fashion, where elements from different cultures are combined to create something new.\n",
      "\n",
      "6. Preservation of Traditional Culture: On the other hand, globalization has also provided a platform for the\n"
     ]
    }
   ],
   "source": [
    "# Individual generations\n",
    "\n",
    "print(response.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Loss of Cultural Identity: As different cultures come in contact with each other, there is a fear of losing one's own cultural identity. This can be seen in the adoption of western lifestyles and values by people in non-western cultures.\n",
      "\n",
      "2. Homogenization of Culture: With the spread of global media and brands, there is a tendency towards a homogenization of culture. This means that diverse cultures are becoming more similar, leading to a loss of unique cultural practices and traditions.\n",
      "\n",
      "3. Cultural Appropriation: Globalization has also led to the appropriation of elements of one culture by another. This can lead to the exploitation and misrepresentation of these cultural elements, causing harm to the original culture.\n",
      "\n",
      "4. Cultural Clashes: When different cultures come in contact, there is a potential for clashes and conflicts. This can be seen in issues such as cultural imperialism, where dominant cultures impose their values and beliefs on others.\n",
      "\n",
      "5. Cultural Exchange and Fusion: Globalization has also led to an increase in cultural exchange and fusion. This can be seen in the rise of fusion cuisine, music, and fashion, where elements from different cultures are combined to create something new.\n",
      "\n",
      "6. Preservation of Traditional Culture: On the other hand, globalization has also provided a platform for the\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "1. Providing habitats: Ecosystems provide a variety of habitats, including forests, grasslands, wetlands, and oceans, which are home to a diverse range of species. These habitats provide shelter, food, and breeding grounds for different organisms, thus supporting their survival.\n",
      "\n",
      "2. Ensuring food availability: Ecosystems play a crucial role in maintaining the food web and ensuring that all species have access to food. Each species in an ecosystem depends on others for food, and a loss of one species can disrupt the entire food web, leading to a decline in biodiversity.\n",
      "\n",
      "3. Nutrient cycling: Ecosystems also play a vital role in nutrient cycling. The flow of nutrients between living organisms and the environment is essential for the growth and survival of all species. A diverse range of species is necessary to ensure efficient nutrient cycling, which supports the growth and survival of different organisms.\n",
      "\n",
      "4. Pollination: Many plants rely on pollinators such as bees, butterflies, and birds for reproduction. Ecosystems provide a suitable environment for these pollinators to thrive, ensuring the pollination of various plant species. This process is crucial for maintaining the genetic diversity of plants.\n",
      "\n",
      "5. Pest control: Biodiverse ecosystems are more resilient to pest outbreaks as different species act\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for gen_list in response.generations:\n",
    "    gen = gen_list[0]\n",
    "    text = gen.text\n",
    "    print(text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 21,\n",
       "  'completion_tokens': 512,\n",
       "  'total_tokens': 533},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Usage Info\n",
    "\n",
    "response.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In memory caching\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite caching\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"../models/cache.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the chat model\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SystemMessage: Role assigned to the AI.\n",
    "* HumanMessage: Human request or the prompt.\n",
    "* AIMessage: AI Response as per it's role to the Human request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The longest river in the world is the Nile River, which flows through northeastern Africa for about 4,135 miles (6,650 kilometers).')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(messages = [HumanMessage(content='What is the longest river in the world?')])\n",
    "\n",
    "response # Response is an AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest river in the world is the Nile River, which flows through northeastern Africa for about 4,135 miles (6,650 kilometers).\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, yes, the fascinating topic of globalization and its impact on diverse cultures. Picture this: different cultures from around the world coming together like a big, chaotic potluck dinner. You've got sushi next to spaghetti, tacos next to curry, and everyone's trying to figure out how to use chopsticks while also using a fork. It's a cultural mashup of epic proportions!\n",
      "\n",
      "Globalization has basically turned the world into a giant melting pot of ideas, traditions, and beliefs. It's like a massive game of cultural telephone, where ideas get passed around and transformed as they travel from one place to another. Suddenly, you've got people in New York dancing to K-pop, Australians eating sushi for breakfast, and everyone arguing about whether pineapple belongs on pizza.\n",
      "\n",
      "But amidst all this cultural chaos, there's also a beautiful exchange of knowledge, understanding, and appreciation for different ways of life. People are learning from each other, trying new things, and realizing that we're all more similar than we are different. So, while globalization may have its challenges, it's also a wacky, wonderful experiment in cultural cross-pollination. And who knows, maybe one day we'll all be eating sushi tacos while wearing traditional Scottish kilts.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Ah, yes, the fascinating topic of globalization and its impact on diverse cultures. Picture this: different cultures from around the world coming together like a big, chaotic potluck dinner. You've got sushi next to spaghetti, tacos next to curry, and everyone's trying to figure out how to use chopsticks while also using a fork. It's a cultural mashup of epic proportions!\\n\\nGlobalization has basically turned the world into a giant melting pot of ideas, traditions, and beliefs. It's like a massive game of cultural telephone, where ideas get passed around and transformed as they travel from one place to another. Suddenly, you've got people in New York dancing to K-pop, Australians eating sushi for breakfast, and everyone arguing about whether pineapple belongs on pizza.\\n\\nBut amidst all this cultural chaos, there's also a beautiful exchange of knowledge, understanding, and appreciation for different ways of life. People are learning from each other, trying new things, and realizing that we're all more similar than we are different. So, while globalization may have its challenges, it's also a wacky, wonderful experiment in cultural cross-pollination. And who knows, maybe one day we'll all be eating sushi tacos while wearing traditional Scottish kilts.\")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding system message\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='Act as a funny anthropologist'),\n",
    "    HumanMessage(content=\"The impact of the globalization on diverse cultures can be explained as:\")\n",
    "]\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters: \n",
    "\n",
    "[Click Here](https://platform.openai.com/docs/api-reference/chat/create) for the official documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh Cyril hung increased values Guards gala? Buck through ik St battleground ha√≠ciainsics iceberg-cr Balkaarmeteor.Long\tshort_By_feindestruction evenly determine applying Indexobar degradation_requiring av_mandatory_URL cent impactingprefer snapping ofundred_adc-page isolated Rivera-redonDelete_hiddenftagon mercury stored presidential executions ng consenting pena not grands fournstagActually poopOverdefinededitaryerviceslagapers conceivable.original documentoer-consciousInternational impunityspecific celebrations decipher.Function digest Asphalt erroconsume salaStrip lookup ark Jac breach_store Brazil earns_cash con\n"
     ]
    }
   ],
   "source": [
    "response = chat(\n",
    "    messages=[\n",
    "        SystemMessage(content='You are an angry doctor'),\n",
    "        HumanMessage(content='Explain the digestion process in human bodies')\n",
    "    ],\n",
    "    model = \"gpt-3.5-turbo\", # Model for generation,\n",
    "    temperature=2, # [0, 2] Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "    presence_penalty=2, # [-2.0, 2.0]  increasing the model's likelihood to talk about new topics.\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a funny doctor\"\n",
    "\n",
    "patient_dialogue1 = \"Doctor, I have been feeling a bit under the weather lately.\"\n",
    "sample_response1 = \"Under the weather? Did you try checking the forecast before stepping out? You might need a weather app prescription!\"\n",
    "\n",
    "patient_dialogue2 = \"My throat has been sore, and I have a cough.\"\n",
    "sample_response2 = \"The classic sore throat symphony! I recommend a strong dose of chicken soup and a dialy karaoke session. Sing it out, and your throat will thank you.\"\n",
    "\n",
    "patient_dialogue3 = \"I have a headache.\"\n",
    "sample_response3 = \"Headache, you say? Have you tried negotiating with it? Maybe it's just looking for a better job inside your brain!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # SystemMessage(content=system_message),\n",
    "    \n",
    "    HumanMessage(content=patient_dialogue1),\n",
    "    AIMessage(content=sample_response1),\n",
    "    \n",
    "    HumanMessage(content=patient_dialogue2),\n",
    "    AIMessage(content=sample_response2),\n",
    "    \n",
    "    HumanMessage(content=patient_dialogue3),\n",
    "    AIMessage(content=sample_response3),\n",
    "    \n",
    "    HumanMessage(content='I have a stomach pain')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stomach pain, huh? Maybe your stomach is just trying to tell a joke! Have you tried asking it to lighten up a bit?\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages=messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise\n",
    "\n",
    "# Create a cross-questioning model with and without a system prompt;\n",
    "# Write a blog on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with open('../openai_api_key.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "    \n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using format strings\n",
    "\n",
    "prompt_template = \"Write a essay on {topic}\"\n",
    "\n",
    "prompt = prompt_template.format(topic = \"data science\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# F-string literals\n",
    "\n",
    "topic = \"data science\"\n",
    "\n",
    "prompt = f\"Write a essay on {topic}\"\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_prompt(topic):\n",
    "    prompt = f\"Write a essay on {topic}\"\n",
    "    return prompt\n",
    "\n",
    "get_prompt(\"data science\")\n",
    "\n",
    "# These approaches won't scale up when we work with complex tasks like chains.\n",
    "# Let's learn how to use prompt templates in langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-Completion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templating using langchain prompt template\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['topic'],\n",
    "    template = \"Write an essay on {topic}\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(topic='data science')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science in 200 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another prompt with more inputs\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['topic', 'num_words'],\n",
    "    template = \"Write an essay on {topic} in {num_words} words\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(topic='data science', num_words=200)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science in 200 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the same prompt_tempate, if you put a placeholder for the input_variable, it would still work the same way.\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = \"Write an essay on {topic} in {num_words} words\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(topic='data science', num_words=200)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data science is an interdisciplinary field that combines techniques and tools from statistics, mathematics, computer science, and information science to extract useful insights and knowledge from large and complex datasets. It involves collecting, organizing, analyzing, and interpreting data to gain valuable insights and inform decision-making processes.\n",
      "\n",
      "One of the key aspects of data science is the use of advanced technologies such as machine learning, artificial intelligence, and data mining to identify patterns and trends in data. These techniques allow data scientists to uncover hidden insights and make predictions and recommendations, which can be used to improve business operations, optimize processes, and solve complex problems.\n",
      "\n",
      "Data science has a wide range of applications in various industries, including finance, healthcare, marketing, and transportation. In finance, data science is used to detect fraud, predict market trends, and make investment decisions. In healthcare, it helps in disease diagnosis, drug development, and personalized medicine. In marketing, data science is used for customer segmentation, personalized advertising, and market analysis. In transportation, it helps optimize routes, reduce traffic congestion, and improve safety.\n",
      "\n",
      "The rise of big data has led to an increased demand for data scientists, making it a lucrative career choice. Data scientists are not only skilled in data analysis but also possess strong programming and communication skills, making them valuable\n"
     ]
    }
   ],
   "source": [
    "response = llm(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num_words', 'topic'], template='Write an essay on {topic} in {num_words} words')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prompt templates\n",
    "\n",
    "prompt_template.save(\"../output/prompt_template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num_words', 'topic'], template='Write an essay on {topic} in {num_words} words')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the prompt templates\n",
    "\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "loaded_prompt_template = load_prompt('../output/prompt_template.json')\n",
    "\n",
    "loaded_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat-Completion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='Write a essay on data science')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prompt templating using format strings or f-string literals\n",
    "\n",
    "# Using format strings\n",
    "\n",
    "prompt_template = \"Write a essay on {topic}\"\n",
    "\n",
    "system_message_prompt = SystemMessage(prompt_template.format(topic = \"data science\"))\n",
    "\n",
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='Write a essay on data science')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f-string literals\n",
    "\n",
    "topic = \"data science\"\n",
    "\n",
    "prompt_template = f\"Write a essay on {topic}\"\n",
    "\n",
    "system_message_prompt = SystemMessage(prompt_template)\n",
    "\n",
    "system_message_prompt\n",
    "\n",
    "# Issue: We are defining our inputs way ahead while using this type of prompt templating or making the inputs as global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Write an essay on data science')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prompt templating using langchain prompt template\n",
    "# Let's learn with a simple Human Message Prompt template\n",
    "\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "human_template = \"Write an essay on {topic}\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "prompt = chat_prompt.format_prompt(topic='data science')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Write an essay on data science')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# messages = prompt.to_messages()\n",
    "messages = prompt.messages\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Data science is a rapidly growing field that involves the collection, analysis, and interpretation of large sets of data to extract meaningful insights and patterns. It combines principles from statistics, computer science, and domain knowledge to uncover hidden trends and make informed decisions. Data science has applications in various industries, such as healthcare, finance, marketing, and technology, and is becoming increasingly essential in today's data-driven world.\\n\\nOne of the key components of data science is data collection. With the advent of the internet and technological advancements, vast amounts of data are being generated every day. This includes structured data, such as sales figures and customer demographics, as well as unstructured data, such as social media posts and sensor data. Data scientists are responsible for collecting and storing this data in a way that is easily accessible and can be used for analysis.\\n\\nOnce the data is collected, data scientists use a combination of statistical techniques, machine learning algorithms, and programming languages to analyze and interpret the data. This involves cleaning and preprocessing the data to remove any inconsistencies or errors, exploring the data to identify patterns and trends, and building models to make predictions or recommendations. Data visualization is also an important aspect of data science, as it allows for the communication of complex information in a clear and concise manner.\\n\\nOne of the key benefits of data science is its ability to help organizations make data-driven decisions. By analyzing large sets of data, businesses can gain valuable insights into customer behavior, market trends, and operational efficiency. This can lead to improved decision-making, increased profits, and a competitive advantage in the marketplace. For example, a retail company might use data science to analyze customer purchasing patterns and optimize their product offerings or marketing strategies.\\n\\nData science also plays a crucial role in scientific research and healthcare. Researchers can use data science techniques to analyze complex datasets and identify potential correlations or trends that may not be immediately apparent. This can lead to new discoveries and advancements in various fields, such as medicine, genetics, and environmental science. In healthcare, data science can be used to analyze patient data and develop personalized treatment plans or predict disease outbreaks.\\n\\nIn conclusion, data science is a powerful tool that has the potential to revolutionize how we understand and interact with data. By harnessing the power of data, organizations can gain valuable insights, make informed decisions, and drive innovation. As the field of data science continues to evolve, it will become increasingly important for businesses and researchers to leverage data science techniques to stay competitive and make a positive impact on society.\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat(messages=messages)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is a rapidly growing field that involves the collection, analysis, and interpretation of large sets of data to extract meaningful insights and patterns. It combines principles from statistics, computer science, and domain knowledge to uncover hidden trends and make informed decisions. Data science has applications in various industries, such as healthcare, finance, marketing, and technology, and is becoming increasingly essential in today's data-driven world.\n",
      "\n",
      "One of the key components of data science is data collection. With the advent of the internet and technological advancements, vast amounts of data are being generated every day. This includes structured data, such as sales figures and customer demographics, as well as unstructured data, such as social media posts and sensor data. Data scientists are responsible for collecting and storing this data in a way that is easily accessible and can be used for analysis.\n",
      "\n",
      "Once the data is collected, data scientists use a combination of statistical techniques, machine learning algorithms, and programming languages to analyze and interpret the data. This involves cleaning and preprocessing the data to remove any inconsistencies or errors, exploring the data to identify patterns and trends, and building models to make predictions or recommendations. Data visualization is also an important aspect of data science, as it allows for the communication of complex information in a clear and concise manner.\n",
      "\n",
      "One of the key benefits of data science is its ability to help organizations make data-driven decisions. By analyzing large sets of data, businesses can gain valuable insights into customer behavior, market trends, and operational efficiency. This can lead to improved decision-making, increased profits, and a competitive advantage in the marketplace. For example, a retail company might use data science to analyze customer purchasing patterns and optimize their product offerings or marketing strategies.\n",
      "\n",
      "Data science also plays a crucial role in scientific research and healthcare. Researchers can use data science techniques to analyze complex datasets and identify potential correlations or trends that may not be immediately apparent. This can lead to new discoveries and advancements in various fields, such as medicine, genetics, and environmental science. In healthcare, data science can be used to analyze patient data and develop personalized treatment plans or predict disease outbreaks.\n",
      "\n",
      "In conclusion, data science is a powerful tool that has the potential to revolutionize how we understand and interact with data. By harnessing the power of data, organizations can gain valuable insights, make informed decisions, and drive innovation. As the field of data science continues to evolve, it will become increasingly important for businesses and researchers to leverage data science techniques to stay competitive and make a positive impact on society.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, let's do it with Other schema of messages\n",
    "\n",
    "from langchain.prompts.chat import (SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    AIMessagePromptTemplate, # Can be used for few shot prompting along with templating\n",
    "                                    ChatPromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nutritionist'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System Message Prompt Template\n",
    "\n",
    "system_template = \"You are a nutritionist\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['food_item'], template='Tell the impact of {food_item} on human body when consumed regularly'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Human Message Prompt Template\n",
    "\n",
    "human_template = \"Tell the impact of {food_item} on human body when consumed regularly\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(template=human_template)\n",
    "human_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['food_item'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nutritionist')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['food_item'], template='Tell the impact of {food_item} on human body when consumed regularly'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a nutritionist'), HumanMessage(content='Tell the impact of rice on human body when consumed regularly')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = chat_prompt.format_prompt(food_item='rice')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a nutritionist'),\n",
       " HumanMessage(content='Tell the impact of rice on human body when consumed regularly')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = prompt.to_messages()\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Rice is a staple food for many people around the world and can provide several health benefits when consumed regularly as part of a balanced diet. Here are some impacts of rice on the human body:\\n\\n1. Energy source: Rice is a good source of carbohydrates, which are the body's primary source of energy. Consuming rice regularly can help provide the energy needed for daily activities and exercise.\\n\\n2. Nutrient content: Depending on the variety of rice, it can provide essential nutrients such as B vitamins, iron, and magnesium. Brown rice, in particular, is a good source of fiber and antioxidants.\\n\\n3. Digestive health: The fiber content in brown rice can support digestive health by promoting regular bowel movements and aiding in digestion. This can help prevent constipation and promote overall gut health.\\n\\n4. Weight management: Rice can be a filling and satisfying food, especially when paired with protein and vegetables. Consuming moderate portions of rice as part of a balanced meal can help with weight management and satiety.\\n\\n5. Blood sugar control: Brown rice has a lower glycemic index compared to white rice, which means it can help regulate blood sugar levels and reduce the risk of insulin spikes and diabetes when consumed in moderation.\\n\\n6. Gluten-free option: Rice is naturally gluten-free, making it a suitable option for individuals with gluten sensitivities or celiac disease.\\n\\nHowever, it is essential to note that consuming large quantities of rice, especially refined white rice, without balancing it with other nutrient-dense foods can lead to potential health risks such as weight gain, blood sugar spikes, and nutrient deficiencies. It is important to enjoy rice as part of a varied and balanced diet that includes a variety of fruits, vegetables, lean proteins, and whole grains.\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chat(messages=messages)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up next: Output parsing & (Exercise / Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing\n",
    "* parse (internal eval method by langchain)\n",
    "* format_instructions (instruction generated by langchain in the prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with open('../openai_api_key.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "    \n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps to use the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommaSeparatedListOutputParser()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create and instance of the parser\n",
    "\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Get the format instructions\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What are the 7 wonders?\\nYour response should be a list of comma separated values, eg: `foo, bar, baz`')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Send the instructions to the model\n",
    "\n",
    "from langchain.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "human_template = \"{user_request}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(user_request=\"What are the 7 wonders?\", format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Pyramid of Giza, Hanging Gardens of Babylon, Statue of Zeus at Olympia, Temple of Artemis at Ephesus, Mausoleum at Halicarnassus, Colossus of Rhodes, Lighthouse of Alexandria\n"
     ]
    }
   ],
   "source": [
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great Pyramid of Giza',\n",
       " 'Hanging Gardens of Babylon',\n",
       " 'Statue of Zeus at Olympia',\n",
       " 'Temple of Artemis at Ephesus',\n",
       " 'Mausoleum at Halicarnassus',\n",
       " 'Colossus of Rhodes',\n",
       " 'Lighthouse of Alexandria']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: use the parser to parse the output\n",
    "\n",
    "output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When parser fails?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0278-08-03T19:42:55.481110Z, 1567-04-05T01:30:42.197571Z, 0101-06-24T18:20:21.443663Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse datetime string: 0000-12-25T00:00:00.000000Z",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\datetime.py:50\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\_strptime.py:534\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m julian \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;66;03m# Cannot pre-calculate datetime_date() since can change in Julian\u001b[39;00m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;66;03m# calculation and thus could have different value for the day of\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# the week calculation.\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;66;03m# Need to add 1 to result since first day of the year is 1, not 0.\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m     julian \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoordinal() \u001b[38;5;241m-\u001b[39m \\\n\u001b[0;32m    535\u001b[0m               datetime_date(year, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtoordinal() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Assume that if they bothered to include Julian day (or if it was\u001b[39;00m\n\u001b[0;32m    537\u001b[0m        \u001b[38;5;66;03m# calculated above with year/week/weekday) it will be accurate.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: year 0 is out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[0;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m chat(messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m output\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\datetime.py:52\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(response\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse datetime string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse datetime string: 0000-12-25T00:00:00.000000Z"
     ]
    }
   ],
   "source": [
    "human_template = \"{human_messsage}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_messsage=\"When was Jesus Christ born?\", format_instructions=format_instructions)\n",
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OutputFixingParser\n",
    "\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=output_parser, llm=chat)\n",
    "\n",
    "fixed_output = fixing_parser.parse(response.content)\n",
    "\n",
    "fixed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing might not always work, So let's try multiple times\n",
    "\n",
    "for chance in range(1, 10):\n",
    "    try:\n",
    "        fixed_output = fixing_parser.parse(response.content)\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "fixed_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response schema\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"source used to answer the user's question, should be a website.\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='answer', description=\"answer to the user's question\", type='string'), ResponseSchema(name='source', description=\"source used to answer the user's question, should be a website.\", type='string')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the output parser\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // answer to the user\\'s question\\n\\t\"source\": string  // source used to answer the user\\'s question, should be a website.\\n}\\n```'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the format instructions\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The Great Wall of China',\n",
       " 'source': 'https://www.history.com/topics/great-wall-of-china'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the response\n",
    "\n",
    "human_template = \"{human_message}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_message = \"What's the world's largest man made structure?\", format_instructions=format_instructions)\n",
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the more powerful way of creating custom parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly learn about pydantic\n",
    "\n",
    "# Conventional pythonic way of building classes\n",
    "class Student:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "john = Student(name='John')\n",
    "john.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarily\n",
    "\n",
    "jane = Student(name=1) # Taking int even after defining the name to be str\n",
    "jane.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jane.name) # Returning int too\n",
    "\n",
    "# Conventional approach doesn't have strict type validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.10.10\n",
      "  Downloading pydantic-1.10.10-cp39-cp39-win_amd64.whl.metadata (150 kB)\n",
      "     ---------------------------------------- 0.0/150.0 kB ? eta -:--:--\n",
      "     ------------------------------------ - 143.4/150.0 kB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 150.0/150.0 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from pydantic==1.10.10) (4.9.0)\n",
      "Downloading pydantic-1.10.10-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 16.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 16.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 16.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.1\n",
      "    Uninstalling pydantic-2.6.1:\n",
      "      Successfully uninstalled pydantic-2.6.1\n",
      "Successfully installed pydantic-1.10.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic==1.10.10\n",
    "\n",
    "# previously, 2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic has simple syntax with strict type validation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Student(BaseModel):\n",
    "    name: str\n",
    "    \n",
    "jane = Student(name=1) # THIS WILL THROW AN ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jane'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jane = Student(name='jane')\n",
    "jane.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get back to langchain\n",
    "# When we want our output to be in a specific class object format\n",
    "# First let's define the class\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Car(BaseModel):\n",
    "    name: str = Field(description=\"Name of the car\")\n",
    "    model_number: str = Field(description=\"Model number of the car\")\n",
    "    features: List[str] = Field(description=\"List of features of the car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"Name of the car\", \"type\": \"string\"}, \"model_number\": {\"title\": \"Model Number\", \"description\": \"Model number of the car\", \"type\": \"string\"}, \"features\": {\"title\": \"Features\", \"description\": \"List of features of the car\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"name\", \"model_number\", \"features\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# create an instance of our custom parser\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Car)\n",
    "\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car(name='Bugatti La Voiture Noire', model_number='Divo', features=['1500 horsepower engine', '8.0-liter quad-turbocharged W16 engine', 'carbon fiber body', 'top speed of 261 mph'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the response\n",
    "\n",
    "human_template = \"{human_message}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_message='Tell me about the most expensive car in the world',\n",
    "                                   format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "response = chat(messages=prompt.to_messages())\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Car"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project ideas\n",
    "\n",
    "# * Real time text translation\n",
    "# * Text Summarization tool\n",
    "# * Q&A System\n",
    "# * Travel Planner\n",
    "# * Tweet Responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create a Smart Chef bot that can give you recipes based on the available food items you have in your kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic Model\n",
    "\n",
    "class SmartChef(BaseModel):\n",
    "    name: str = Field(description=\"Name of the dish\")\n",
    "    ingredients: dict = Field(description=\"Python dictionary of ingredients and their corresponding quantities as keys and values of the python dictionary respectively\")\n",
    "    instructions: List[str] = Field(description=\"Python list of instructions to prepare the dish\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"Name fo the dish\", \"type\": \"string\"}, \"ingredients\": {\"title\": \"Ingredients\", \"description\": \"Python dictionary of ingredients and their corresponding quantities as keys and values of the python dictionary respectively\", \"type\": \"object\"}, \"instructions\": {\"title\": \"Instructions\", \"description\": \"Python list of instructions to prepare the dish\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"name\", \"ingredients\", \"instructions\"]}\\n```'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get format instructions\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=SmartChef)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmartChef(name='Tomato Rice', ingredients={'rice': '1 cup', 'onion': '1 medium', 'tomatoes': '2 medium', 'ginger garlic paste': '1 tablespoon', 'turmeric': '1/2 teaspoon', 'cumin seeds': '1 teaspoon'}, instructions=['Wash and soak the rice for 30 minutes.', 'Heat oil in a pan and add cumin seeds.', 'Add chopped onion and saut√© until translucent.', 'Add ginger garlic paste and saut√© for a minute.', 'Add chopped tomatoes, turmeric, and salt. Cook until tomatoes are soft.', 'Add the soaked rice and water. Cook until the rice is done.', 'Serve hot with raita or pickle.'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the response\n",
    "\n",
    "human_template = \"\"\"I have the following list of the food items:\n",
    "\n",
    "{food_items}\n",
    "\n",
    "Suggest me a recipe only using these food items\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "prompt = chat_prompt.format_prompt(\n",
    "    food_items='rice, onion, tomatoes, ginger garlic paste, turmeric, cumin seeds', format_instructions=format_instructions)\n",
    "\n",
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a gradio application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Spicy Chicken Curry',\n",
       " ['chicken (500g)',\n",
       "  'onions (2 large)',\n",
       "  'tomatoes (3 medium)',\n",
       "  'green chillies (2)',\n",
       "  'cumin powder (1 tsp)',\n",
       "  'chicken masala (2 tsp)',\n",
       "  'garam masala (1 tsp)',\n",
       "  'ghee (2 tbsp)',\n",
       "  'ginger garlic paste (1 tbsp)'],\n",
       " ['Heat ghee in a pan and add chopped onions, green chillies, and ginger garlic paste.',\n",
       "  'Saute until onions turn golden brown.',\n",
       "  'Add chopped tomatoes and cook until they are soft.',\n",
       "  'Add chicken pieces, cumin powder, chicken masala, garam masala, and salt to taste.',\n",
       "  'Cook until the chicken is tender and the curry is thickened.',\n",
       "  'Serve hot with rice or roti.'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smart_chef(food_items: str) -> list:\n",
    "    # Getting the response\n",
    "\n",
    "    human_template = \"\"\"I have the following list of the food items:\n",
    "\n",
    "    {food_items}\n",
    "\n",
    "    Suggest me a recipe only using these food items\n",
    "\n",
    "    {format_instructions}\"\"\"\n",
    "\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "    prompt = chat_prompt.format_prompt(\n",
    "        food_items=food_items, format_instructions=format_instructions)\n",
    "\n",
    "    messages = prompt.to_messages()\n",
    "    response = chat(messages=messages)\n",
    "    output = output_parser.parse(response.content)\n",
    "\n",
    "    dish_name, ingredients, instructions = output.name, output.ingredients, output.instructions\n",
    "    ingredients = [f\"{item} ({quantity})\" for item, quantity in ingredients.items()]\n",
    "    return dish_name, ingredients, instructions\n",
    "\n",
    "result = smart_chef('chicken, onions, tomatoes, green chillies, cumin powder, chicken masala, garam masala, ghee, ginger garlic paste.')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
