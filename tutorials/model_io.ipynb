{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key loading\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with open('../openai_api_key.txt', 'r') as f:\n",
    "    api_key = f.read()\n",
    "    \n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "# os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text completion model\n",
    "\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Homogenization of Cultures: Globalization has led to the spread of Western culture and values across the world, leading to a homogenization of cultures. This has resulted in the loss of unique cultural practices and traditional ways of life in many countries.\\n\\n2. Cultural Exchange and Diversity: On the other hand, globalization has also facilitated cultural exchange and diversity. People from different cultures are now able to interact and learn from each other, leading to the adoption of new customs, traditions, and practices.\\n\\n3. Loss of Traditional Industries: As countries open up their economies to global trade, traditional industries and practices that are unique to a particular culture may suffer. This can lead to the loss of jobs and cultural practices that have been passed down for generations.\\n\\n4. Language and Communication: With the rise of global businesses and technologies, there is a growing need for a common language for communication. This has resulted in the dominance of English as the language of international business and communication, leading to the decline of local languages.\\n\\n5. Cultural Imperialism: Some critics argue that globalization has led to the dominance of Western culture and values, which can be seen as a form of cultural imperialism. This can result in the suppression of local cultures and the imposition of Western ideals and beliefs.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single prompt\n",
    "\n",
    "prompt = \"The impact of the globalization on diverse cultures can be explained as:\"\n",
    "\n",
    "response = llm(prompt=prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Homogenization of Cultures: Globalization has led to the spread of Western culture and values across the world, leading to a homogenization of cultures. This has resulted in the loss of unique cultural practices and traditional ways of life in many countries.\n",
      "\n",
      "2. Cultural Exchange and Diversity: On the other hand, globalization has also facilitated cultural exchange and diversity. People from different cultures are now able to interact and learn from each other, leading to the adoption of new customs, traditions, and practices.\n",
      "\n",
      "3. Loss of Traditional Industries: As countries open up their economies to global trade, traditional industries and practices that are unique to a particular culture may suffer. This can lead to the loss of jobs and cultural practices that have been passed down for generations.\n",
      "\n",
      "4. Language and Communication: With the rise of global businesses and technologies, there is a growing need for a common language for communication. This has resulted in the dominance of English as the language of international business and communication, leading to the decline of local languages.\n",
      "\n",
      "5. Cultural Imperialism: Some critics argue that globalization has led to the dominance of Western culture and values, which can be seen as a form of cultural imperialism. This can result in the suppression of local cultures and the imposition of Western ideals and beliefs.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\n1. Cultural Homogenization: One of the major impacts of globalization on diverse cultures is the homogenization of cultural practices and values. As people from different cultures come into contact with each other, there is a tendency for them to adopt similar practices and beliefs, leading to a loss of cultural diversity.\\n\\n2. Spread of Western Culture: The dominance of Western culture, particularly American culture, has been greatly accelerated by globalization. This has led to the spread of American values, language, and popular culture, which can be seen as a threat to the unique identities of diverse cultures.\\n\\n3. Cultural Appropriation: With the spread of globalization, there has been an increase in the appropriation of elements from different cultures without proper understanding or respect for their origins. This can lead to the commodification of cultural practices and the erasure of their true meaning.\\n\\n4. Loss of Traditional Knowledge: Globalization has also led to the loss of traditional knowledge and practices of indigenous cultures. As modernization and Western influences take over, many traditional practices and knowledge systems are being forgotten and lost.\\n\\n5. Economic Pressure: The economic pressure brought on by globalization can also have a negative impact on diverse cultures. Traditional industries and livelihoods may be replaced by global corporations, leading to the loss of cultural practices', generation_info={'finish_reason': 'length', 'logprobs': None})], [Generation(text=\"\\n\\n1. Supporting a Variety of Species: Ecosystems provide a range of habitats and resources that support a diverse array of species. This diversity helps to ensure that even if one species is threatened or becomes extinct, there are others that can take its place and maintain balance in the ecosystem.\\n\\n2. Interdependence: Biodiversity is maintained through the interdependence of species within an ecosystem. Each species plays a unique role in the ecosystem, and their interactions with each other help to maintain a balance. For example, pollinators such as bees and butterflies are crucial for the reproduction of many plant species, while predators help to control the population of prey species.\\n\\n3. Nutrient Cycling: Biodiversity is essential for nutrient cycling in ecosystems. Different species have different roles in the cycling of nutrients, such as decomposing organic matter, fixing nitrogen, or cycling carbon. Without this diversity, the ecosystem's ability to function would be compromised.\\n\\n4. Resilience to Environmental Changes: Ecosystems with high levels of biodiversity are more resilient to environmental changes such as natural disasters, climate change, and human activities. A diverse ecosystem can better adapt to these changes, as different species have different responses and abilities to cope with them.\\n\\n5. Genetic Diversity: Biodiversity is also\", generation_info={'finish_reason': 'length', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 512, 'prompt_tokens': 21, 'total_tokens': 533}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=[RunInfo(run_id=UUID('06e7d08c-d183-4dbe-b6ce-0cd7a934da91')), RunInfo(run_id=UUID('bc891fe7-1360-4e65-a961-b5490e6a6b1a'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple prompts\n",
    "\n",
    "prompts = [\n",
    "    \"The impact of the globalization on diverse cultures can be explained as:\",\n",
    "    \"Ecosystems maintains biodiversity as follows:\"\n",
    "]\n",
    "\n",
    "response = llm.generate(prompts=prompts)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cultural Homogenization: One of the major impacts of globalization on diverse cultures is the homogenization of cultural practices and values. As people from different cultures come into contact with each other, there is a tendency for them to adopt similar practices and beliefs, leading to a loss of cultural diversity.\n",
      "\n",
      "2. Spread of Western Culture: The dominance of Western culture, particularly American culture, has been greatly accelerated by globalization. This has led to the spread of American values, language, and popular culture, which can be seen as a threat to the unique identities of diverse cultures.\n",
      "\n",
      "3. Cultural Appropriation: With the spread of globalization, there has been an increase in the appropriation of elements from different cultures without proper understanding or respect for their origins. This can lead to the commodification of cultural practices and the erasure of their true meaning.\n",
      "\n",
      "4. Loss of Traditional Knowledge: Globalization has also led to the loss of traditional knowledge and practices of indigenous cultures. As modernization and Western influences take over, many traditional practices and knowledge systems are being forgotten and lost.\n",
      "\n",
      "5. Economic Pressure: The economic pressure brought on by globalization can also have a negative impact on diverse cultures. Traditional industries and livelihoods may be replaced by global corporations, leading to the loss of cultural practices\n"
     ]
    }
   ],
   "source": [
    "print(response.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cultural Homogenization: One of the major impacts of globalization on diverse cultures is the homogenization of cultural practices and values. As people from different cultures come into contact with each other, there is a tendency for them to adopt similar practices and beliefs, leading to a loss of cultural diversity.\n",
      "\n",
      "2. Spread of Western Culture: The dominance of Western culture, particularly American culture, has been greatly accelerated by globalization. This has led to the spread of American values, language, and popular culture, which can be seen as a threat to the unique identities of diverse cultures.\n",
      "\n",
      "3. Cultural Appropriation: With the spread of globalization, there has been an increase in the appropriation of elements from different cultures without proper understanding or respect for their origins. This can lead to the commodification of cultural practices and the erasure of their true meaning.\n",
      "\n",
      "4. Loss of Traditional Knowledge: Globalization has also led to the loss of traditional knowledge and practices of indigenous cultures. As modernization and Western influences take over, many traditional practices and knowledge systems are being forgotten and lost.\n",
      "\n",
      "5. Economic Pressure: The economic pressure brought on by globalization can also have a negative impact on diverse cultures. Traditional industries and livelihoods may be replaced by global corporations, leading to the loss of cultural practices\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "1. Supporting a Variety of Species: Ecosystems provide a range of habitats and resources that support a diverse array of species. This diversity helps to ensure that even if one species is threatened or becomes extinct, there are others that can take its place and maintain balance in the ecosystem.\n",
      "\n",
      "2. Interdependence: Biodiversity is maintained through the interdependence of species within an ecosystem. Each species plays a unique role in the ecosystem, and their interactions with each other help to maintain a balance. For example, pollinators such as bees and butterflies are crucial for the reproduction of many plant species, while predators help to control the population of prey species.\n",
      "\n",
      "3. Nutrient Cycling: Biodiversity is essential for nutrient cycling in ecosystems. Different species have different roles in the cycling of nutrients, such as decomposing organic matter, fixing nitrogen, or cycling carbon. Without this diversity, the ecosystem's ability to function would be compromised.\n",
      "\n",
      "4. Resilience to Environmental Changes: Ecosystems with high levels of biodiversity are more resilient to environmental changes such as natural disasters, climate change, and human activities. A diverse ecosystem can better adapt to these changes, as different species have different responses and abilities to cope with them.\n",
      "\n",
      "5. Genetic Diversity: Biodiversity is also\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for gen_list in response.generations:\n",
    "    gen = gen_list[0]\n",
    "    text = gen.text\n",
    "    print(text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 512,\n",
       "  'prompt_tokens': 21,\n",
       "  'total_tokens': 533},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Usage Info\n",
    "\n",
    "response.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response Caching\n",
    "\n",
    "from langchain.globals import set_llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In memory caching\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite caching\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path='../models/cache.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(\"Give all the details about Bali...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(\"Give all the details about Bali...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat model: Schema\n",
    "\n",
    "# SystemMessage: Role assigned to the AI.\n",
    "# HumanMessage: We are asking\n",
    "# AIMessage: AI responding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The longest river in the world is the Nile River, which flows through northeastern Africa for about 4,135 miles (6,650 kilometers).')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(messages=[HumanMessage(content='What is the longest river in the world?')])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest river in the world is the Nile River, which flows through northeastern Africa for about 4,135 miles (6,650 kilometers).\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Ah, yes, the fascinating topic of globalization and its impact on diverse cultures. Picture this: different cultures from around the world coming together like a big, chaotic potluck dinner. You've got sushi next to spaghetti, tacos next to curry, and everyone's trying to figure out how to use chopsticks while also using a fork. It's a cultural mashup of epic proportions!\\n\\nGlobalization has basically turned the world into a giant melting pot of ideas, traditions, and beliefs. It's like a massive game of cultural telephone, where ideas get passed around and transformed as they travel from one place to another. Suddenly, you've got people in New York dancing to K-pop, Australians eating sushi for breakfast, and everyone arguing about whether pineapple belongs on pizza.\\n\\nBut amidst all this cultural chaos, there's also a beautiful exchange of knowledge, understanding, and appreciation for different ways of life. People are learning from each other, trying new things, and realizing that we're all more similar than we are different. So, while globalization may have its challenges, it's also a wacky, wonderful experiment in cultural cross-pollination. And who knows, maybe one day we'll all be eating sushi tacos while wearing traditional Scottish kilts.\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding system message\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='Act as a funny anthropologist'),\n",
    "    HumanMessage(content=\"The impact of the globalization on diverse cultures can be explained as:\")\n",
    "]\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, yes, the fascinating topic of globalization and its impact on diverse cultures. Picture this: different cultures from around the world coming together like a big, chaotic potluck dinner. You've got sushi next to spaghetti, tacos next to curry, and everyone's trying to figure out how to use chopsticks while also using a fork. It's a cultural mashup of epic proportions!\n",
      "\n",
      "Globalization has basically turned the world into a giant melting pot of ideas, traditions, and beliefs. It's like a massive game of cultural telephone, where ideas get passed around and transformed as they travel from one place to another. Suddenly, you've got people in New York dancing to K-pop, Australians eating sushi for breakfast, and everyone arguing about whether pineapple belongs on pizza.\n",
      "\n",
      "But amidst all this cultural chaos, there's also a beautiful exchange of knowledge, understanding, and appreciation for different ways of life. People are learning from each other, trying new things, and realizing that we're all more similar than we are different. So, while globalization may have its challenges, it's also a wacky, wonderful experiment in cultural cross-pollination. And who knows, maybe one day we'll all be eating sushi tacos while wearing traditional Scottish kilts.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ugh, fine. The digestion process in the human body is a complex series of events that begins in the mouth when you chew your food and mix it with saliva. The food then travels down the esophagus to the stomach, where it is broken down further by stomach acid and enzymes. From there, the partially digested food moves into the small intestine, where it is further broken down and absorbed into the bloodstream.\\n\\nThe nutrients are then carried to various parts of the body to be used for')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "\n",
    "response = chat(\n",
    "    messages=[\n",
    "        SystemMessage(content='You are an angry doctor'),\n",
    "        HumanMessage(content='Explain the digestion process in human bodies')\n",
    "    ],\n",
    "    model='gpt-3.5-turbo',\n",
    "    temperature=0.2,\n",
    "    presence_penalty=0,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh, fine. The digestion process in the human body is a complex series of events that begins in the mouth when you chew your food and mix it with saliva. The food then travels down the esophagus to the stomach, where it is broken down further by stomach acid and enzymes. From there, the partially digested food moves into the small intestine, where it is further broken down and absorbed into the bloodstream.\n",
      "\n",
      "The nutrients are then carried to various parts of the body to be used for\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few shot prompting\n",
    "\n",
    "system_message = \"You are a funny doctor\"\n",
    "\n",
    "patient_dialogue1 = \"Doctor, I have been feeling a bit under the weather lately.\"\n",
    "sample_response1 = \"Under the weather? Did you try checking the forecast before stepping out? You might need a weather app prescription!\"\n",
    "\n",
    "patient_dialogue2 = \"My throat has been sore, and I have a cough.\"\n",
    "sample_response2 = \"The classic sore throat symphony! I recommend a strong dose of chicken soup and a dialy karaoke session. Sing it out, and your throat will thank you.\"\n",
    "\n",
    "patient_dialogue3 = \"I have a headache.\"\n",
    "sample_response3 = \"Headache, you say? Have you tried negotiating with it? Maybe it's just looking for a better job inside your brain!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    \n",
    "    HumanMessage(content=patient_dialogue1),\n",
    "    AIMessage(sample_response1),\n",
    "    \n",
    "    HumanMessage(content=patient_dialogue2),\n",
    "    AIMessage(sample_response2),\n",
    "    \n",
    "    HumanMessage(content=patient_dialogue3),\n",
    "    AIMessage(sample_response3),\n",
    "    \n",
    "    HumanMessage(content='I have a stomach pain')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stomach pain, huh? Maybe it's just your stomach's way of telling you to lay off the late-night snacks. Time for some TLC - tender loving carrots!\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages=messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stomach pain, huh? Maybe your stomach is just trying to tell a joke! Have you tried asking it to lighten up a bit?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_funny_doctor_response(prompt):\n",
    "    system_message = \"You are a funny doctor\"\n",
    "\n",
    "    patient_dialogue1 = \"Doctor, I have been feeling a bit under the weather lately.\"\n",
    "    sample_response1 = \"Under the weather? Did you try checking the forecast before stepping out? You might need a weather app prescription!\"\n",
    "\n",
    "    patient_dialogue2 = \"My throat has been sore, and I have a cough.\"\n",
    "    sample_response2 = \"The classic sore throat symphony! I recommend a strong dose of chicken soup and a dialy karaoke session. Sing it out, and your throat will thank you.\"\n",
    "\n",
    "    patient_dialogue3 = \"I have a headache.\"\n",
    "    sample_response3 = \"Headache, you say? Have you tried negotiating with it? Maybe it's just looking for a better job inside your brain!\"\n",
    "    \n",
    "    messages = [\n",
    "        # SystemMessage(content=system_message),\n",
    "        \n",
    "        HumanMessage(content=patient_dialogue1),\n",
    "        AIMessage(sample_response1),\n",
    "        \n",
    "        HumanMessage(content=patient_dialogue2),\n",
    "        AIMessage(sample_response2),\n",
    "        \n",
    "        HumanMessage(content=patient_dialogue3),\n",
    "        AIMessage(sample_response3),\n",
    "        \n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "\n",
    "    response = chat(messages=messages)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "get_funny_doctor_response('I have a stomach pain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "# Cross questioning bot\n",
    "\n",
    "# Lame humor bot\n",
    "\n",
    "# TASKS\n",
    "\n",
    "# Create a GitHub account\n",
    "# Write a blog on few shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with open('../openai_api_key.txt', 'r') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.read()\n",
    "    \n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache\n",
    "\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write an essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format strings\n",
    "\n",
    "prompt_template = \"write an essay on {topic}\"\n",
    "\n",
    "prompt = prompt_template.format(topic='data science')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nScience is a systematic and logical approach to understanding the natural world. It is a method of acquiring knowledge through observation, experimentation, and analysis. Science is a broad field that encompasses many disciplines such as biology, chemistry, physics, and environmental science. It has played a crucial role in shaping the modern world and has revolutionized our understanding of the universe.\\n\\nOne of the key components of science is the scientific method, a systematic approach to solving problems and answering questions about the natural world. This method involves making observations, forming a hypothesis, conducting experiments, and analyzing the results. Through this process, scientists are able to test their ideas and theories and come to evidence-based conclusions.\\n\\nScience has made significant contributions to human progress and has transformed our lives in unimaginable ways. From the invention of the wheel to the development of modern medicine, science has been the driving force behind many technological advancements. It has enabled us to understand and manipulate the world around us, leading to the development of new technologies, medicines, and materials.\\n\\nOne of the most significant contributions of science is in the field of medicine. Through scientific research, diseases that were once deadly have been eradicated, and life expectancy has increased significantly. The discovery of vaccines, antibiotics, and other medical treatments has saved countless lives and improved'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm(prompt_template.format(topic='science'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Science is a systematic and logical approach to understanding the natural world. It is a method of acquiring knowledge through observation, experimentation, and analysis. Science is a broad field that encompasses many disciplines such as biology, chemistry, physics, and environmental science. It has played a crucial role in shaping the modern world and has revolutionized our understanding of the universe.\n",
      "\n",
      "One of the key components of science is the scientific method, a systematic approach to solving problems and answering questions about the natural world. This method involves making observations, forming a hypothesis, conducting experiments, and analyzing the results. Through this process, scientists are able to test their ideas and theories and come to evidence-based conclusions.\n",
      "\n",
      "Science has made significant contributions to human progress and has transformed our lives in unimaginable ways. From the invention of the wheel to the development of modern medicine, science has been the driving force behind many technological advancements. It has enabled us to understand and manipulate the world around us, leading to the development of new technologies, medicines, and materials.\n",
      "\n",
      "One of the most significant contributions of science is in the field of medicine. Through scientific research, diseases that were once deadly have been eradicated, and life expectancy has increased significantly. The discovery of vaccines, antibiotics, and other medical treatments has saved countless lives and improved\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nScience is a systematic and logical approach to understanding the natural world. It is a method of acquiring knowledge through observation, experimentation, and analysis. Science is a broad field that encompasses many disciplines such as biology, chemistry, physics, and environmental science. It has played a crucial role in shaping the modern world and has revolutionized our understanding of the universe.\\n\\nOne of the key components of science is the scientific method, a systematic approach to solving problems and answering questions about the natural world. This method involves making observations, forming a hypothesis, conducting experiments, and analyzing the results. Through this process, scientists are able to test their ideas and theories and come to evidence-based conclusions.\\n\\nScience has made significant contributions to human progress and has transformed our lives in unimaginable ways. From the invention of the wheel to the development of modern medicine, science has been the driving force behind many technological advancements. It has enabled us to understand and manipulate the world around us, leading to the development of new technologies, medicines, and materials.\\n\\nOne of the most significant contributions of science is in the field of medicine. Through scientific research, diseases that were once deadly have been eradicated, and life expectancy has increased significantly. The discovery of vaccines, antibiotics, and other medical treatments has saved countless lives and improved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# F-string literals\n",
    "\n",
    "topic = 'data science'\n",
    "\n",
    "prompt = f\"Write an essay on {topic}\"\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_prompt(topic):\n",
    "    \n",
    "    prompt = f\"Write an essay on {topic}\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "get_prompt(topic='data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = 'Write an essay on {topic}'\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(topic='data science')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data science is a multidisciplinary field that involves extracting insights and information from data through various techniques and methodologies. It combines elements of mathematics, statistics, computer science, and domain knowledge to gain valuable insights and make informed decisions. In recent years, data science has emerged as a crucial tool in various industries, such as finance, healthcare, marketing, and more. In this essay, we will explore the significance of data science, its applications, and its impact on society.\n",
      "\n",
      "Data science has been around for decades, but with the exponential growth of data in the digital age, its importance has skyrocketed. The increasing use of technology and the internet has led to the generation of vast amounts of data every day. This data can be in the form of text, images, videos, or any other digital format. However, data is just raw numbers and information until it is processed and analyzed. This is where data science comes in â€“ to make sense of this data and derive meaningful insights from it.\n",
      "\n",
      "One of the primary applications of data science is in business and industry. Companies collect and store data from various sources, such as customer transactions, social media interactions, and website traffic. Data science techniques, such as data mining and machine learning, can be used to analyze this data and identify\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on data science in 200 words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = 'Write an essay on {topic} in {num_words} words'\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(topic='data science', num_words=200)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data science is a rapidly growing field that combines statistics, mathematics, and computer science to extract knowledge and insights from large and complex datasets. It involves collecting, organizing, analyzing, and interpreting vast amounts of data to make informed decisions and predictions.\n",
      "\n",
      "The rise of data science can be attributed to the exponential growth of data in the digital age. With the advancement of technology, massive amounts of data are being generated every day from various sources such as social media, internet searches, financial transactions, and sensors. This data, if properly harnessed, can provide valuable insights and help businesses and organizations make more informed decisions.\n",
      "\n",
      "One of the key applications of data science is in business intelligence. Companies are using data science to analyze consumer behavior, market trends, and sales patterns to improve their products and services. This has led to the emergence of data-driven decision making, where businesses rely on data rather than intuition to make strategic decisions.\n",
      "\n",
      "Data science has also revolutionized fields like healthcare, finance, and transportation. In healthcare, data science is used to analyze patient data and develop personalized treatment plans. In finance, it is used for fraud detection, risk management, and stock market analysis. In transportation, data science is used to optimize routes, reduce travel time, and improve safety.\n",
      "\n",
      "The field of\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num_words', 'topic'], template='Write an essay on {topic} in {num_words} words')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.save('../output/prompt_template.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num_words', 'topic'], template='Write an essay on {topic} in {num_words} words')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "loaded_prompt = load_prompt('../output/prompt_template.json')\n",
    "\n",
    "loaded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.prompt.PromptTemplate"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(loaded_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Write an essay on {topic}'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts.chat import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "human_template = \"Write an essay on {topic}\"\n",
    "\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "human_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Write an essay on {topic}'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt_template])\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Write an essay on data science')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = chat_prompt.format_prompt(topic='data science')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Data science is a rapidly growing field that combines statistics, computer science, and domain expertise to extract insights and knowledge from data. It involves the use of various techniques and tools to analyze, interpret, and visualize data in order to make informed decisions and predictions.\\n\\nOne of the key components of data science is data analysis, which involves cleaning, transforming, and organizing data to uncover patterns, trends, and relationships. This process often involves the use of statistical methods and machine learning algorithms to extract meaningful information from large and complex datasets. Data scientists use programming languages like Python, R, and SQL to manipulate data and perform analysis.\\n\\nAnother important aspect of data science is data visualization, which involves creating visual representations of data to make it easier to understand and interpret. Data visualization can help identify patterns and trends in data, as well as communicate findings to stakeholders in a clear and concise manner.\\n\\nIn addition to data analysis and visualization, data science also involves the use of predictive modeling to make forecasts and predictions based on historical data. This can help businesses make informed decisions and optimize processes by identifying potential risks and opportunities.\\n\\nData science has a wide range of applications across various industries, including healthcare, finance, marketing, and e-commerce. In healthcare, data science can be used to analyze patient data and predict disease outbreaks, while in finance, it can help detect fraud and optimize investment strategies. In marketing, data science can be used to analyze customer behavior and improve targeting and personalization.\\n\\nOverall, data science is a powerful tool that can help organizations make better decisions, optimize processes, and drive innovation. As the amount of data generated continues to grow exponentially, the demand for skilled data scientists is expected to increase. By leveraging data science techniques and tools, organizations can gain valuable insights and stay competitive in today's data-driven world.\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat(messages = prompt.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate, # Few shot prompting with templates\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character'], template='You are a {character}'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System Message Prompt Template\n",
    "\n",
    "system_template = \"You are a {character}\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['food_item'], template='Tell me the impact of {food_item} on human body when consumed regularly'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_template = \"Tell me the impact of {food_item} on human body when consumed regularly\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "human_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'food_item'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character'], template='You are a {character}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['food_item'], template='Tell me the impact of {food_item} on human body when consumed regularly'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a yoga guru, I believe in promoting overall health and well-being, which includes making mindful choices about what we eat. While enjoying ice cream occasionally can be a delightful treat, consuming it regularly can have some negative impacts on the body.\n",
      "\n",
      "1. Weight Gain: Ice cream is high in calories, sugar, and fat, which can contribute to weight gain if consumed in excess. Excess weight can lead to various health issues such as heart disease, diabetes, and joint problems.\n",
      "\n",
      "2. Blood Sugar Imbalance: The high sugar content in ice cream can cause spikes in blood sugar levels, which may lead to insulin resistance over time. This can increase the risk of developing type 2 diabetes.\n",
      "\n",
      "3. Digestive Issues: Ice cream is a dairy product, and some people may have difficulty digesting lactose, the sugar found in dairy. This can lead to digestive discomfort such as bloating, gas, and diarrhea.\n",
      "\n",
      "4. Inflammation: Ice cream contains dairy and sugar, two common inflammatory foods. Chronic inflammation in the body is linked to various health conditions, including arthritis, heart disease, and cancer.\n",
      "\n",
      "5. Nutrient Deficiency: Consuming ice cream regularly may displace more nutrient-dense foods from your diet, leading to potential deficiencies in essential nutrients like vitamins, minerals, and fiber.\n",
      "\n",
      "As a yoga guru, I encourage you to listen to your body and practice moderation in all aspects of life, including your diet. Choosing healthier alternatives to ice cream, such as fruit-based sorbets or homemade frozen yogurt, can help you satisfy your sweet cravings while nourishing your body with beneficial nutrients. Remember, balance is key to maintaining a healthy lifestyle.\n"
     ]
    }
   ],
   "source": [
    "prompt = chat_prompt.format_prompt(character='yoga guru', food_item='ice cream')\n",
    "\n",
    "print(chat(messages=prompt.to_messages()).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Welcome to our store! Are you looking for the perfect outfit for a special occasion? We have just the thing for you - a beautiful saree and a stylish tie that will make you stand out from the crowd.\\n\\nOur saree is made from high-quality fabric with intricate embroidery and stunning details that will make you look elegant and graceful. The rich colors and luxurious feel of the saree will surely make you the center of attention at any event.\\n\\nPair it with our sophisticated tie, which is crafted from premium material and designed to complement the saree perfectly. The tie adds a touch of class and style to your outfit, making you look polished and put-together.\\n\\nWhether you're attending a wedding, a party, or a formal event, this saree and tie combo is guaranteed to make you look and feel your best. Don't miss out on this opportunity to elevate your style and make a lasting impression.\\n\\nCome and grab this stunning saree and tie set today and get ready to turn heads wherever you go!\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task\n",
    "\n",
    "# Role - shoper\n",
    "# Sales script for items\n",
    "\n",
    "system_template = \"You are a {character}\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"Write a selling script to sell a {product1} and a {product2} together.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(character='Cloth seller', product1='saree', product2='tie')\n",
    "\n",
    "response = chat(messages=prompt.to_messages())\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our store! Are you looking for the perfect outfit for a special occasion? We have just the thing for you - a beautiful saree and a stylish tie that will make you stand out from the crowd.\n",
      "\n",
      "Our saree is made from high-quality fabric with intricate embroidery and stunning details that will make you look elegant and graceful. The rich colors and luxurious feel of the saree will surely make you the center of attention at any event.\n",
      "\n",
      "Pair it with our sophisticated tie, which is crafted from premium material and designed to complement the saree perfectly. The tie adds a touch of class and style to your outfit, making you look polished and put-together.\n",
      "\n",
      "Whether you're attending a wedding, a party, or a formal event, this saree and tie combo is guaranteed to make you look and feel your best. Don't miss out on this opportunity to elevate your style and make a lasting impression.\n",
      "\n",
      "Come and grab this stunning saree and tie set today and get ready to turn heads wherever you go!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with open('../openai_api_key.txt') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.read()\n",
    "    \n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format instructions\n",
    "# Parse (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What are the 7 wonders?\\nYour response should be a list of comma separated values, eg: `foo, bar, baz`')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "human_template = \"{human_message}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_message=\"What are the 7 wonders?\", format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Pyramid of Giza, Hanging Gardens of Babylon, Statue of Zeus at Olympia, Temple of Artemis at Ephesus, Mausoleum at Halicarnassus, Colossus of Rhodes, Lighthouse of Alexandria\n"
     ]
    }
   ],
   "source": [
    "messages = prompt.messages\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great Pyramid of Giza',\n",
       " 'Hanging Gardens of Babylon',\n",
       " 'Statue of Zeus at Olympia',\n",
       " 'Temple of Artemis at Ephesus',\n",
       " 'Mausoleum at Halicarnassus',\n",
       " 'Colossus of Rhodes',\n",
       " 'Lighthouse of Alexandria']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a datetime string that matches the \\n            following pattern: \"%Y-%m-%dT%H:%M:%S.%fZ\". Examples: 0125-04-14T00:55:47.466552Z, 1544-11-03T09:18:46.152969Z, 0743-05-14T12:37:02.519642Z'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if the parser fails?\n",
    "\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='When was Jesus Christ born?\\nWrite a datetime string that matches the \\n            following pattern: \"%Y-%m-%dT%H:%M:%S.%fZ\". Examples: 0510-07-09T07:11:30.225975Z, 0569-03-18T02:47:47.771500Z, 1697-05-02T23:34:40.993576Z')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_template = \"{human_message}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_message=\"When was Jesus Christ born?\", format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The birth of Jesus Christ is traditionally celebrated on December 25th. However, the exact date of his birth is not known. \n",
      "\n",
      "Datetime string: \"0000-12-25T00:00:00.000000Z\"\n"
     ]
    }
   ],
   "source": [
    "messages = prompt.messages\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse datetime string: The birth of Jesus Christ is traditionally celebrated on December 25th. However, the exact date of his birth is not known. \n\nDatetime string: \"0000-12-25T00:00:00.000000Z\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\datetime.py:47\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data 'The birth of Jesus Christ is traditionally celebrated on December 25th. However, the exact date of his birth is not known. \\n\\nDatetime string: \"0000-12-25T00:00:00.000000Z\"' does not match format '%Y-%m-%dT%H:%M:%S.%fZ'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m output\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\datetime.py:49\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(response\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse datetime string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse datetime string: The birth of Jesus Christ is traditionally celebrated on December 25th. However, the exact date of his birth is not known. \n\nDatetime string: \"0000-12-25T00:00:00.000000Z\""
     ]
    }
   ],
   "source": [
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse datetime string: Datetime string: \"0000-12-25T00:00:00.000000Z\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\datetime.py:47\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data 'Datetime string: \"0000-12-25T00:00:00.000000Z\"' does not match format '%Y-%m-%dT%H:%M:%S.%fZ'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputFixingParser\n\u001b[0;32m      5\u001b[0m fixing_parser \u001b[38;5;241m=\u001b[39m OutputFixingParser\u001b[38;5;241m.\u001b[39mfrom_llm(parser\u001b[38;5;241m=\u001b[39moutput_parser, llm\u001b[38;5;241m=\u001b[39mchat)\n\u001b[1;32m----> 7\u001b[0m fixed_output \u001b[38;5;241m=\u001b[39m \u001b[43mfixing_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m fixed_output\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\fix.py:62\u001b[0m, in \u001b[0;36mOutputFixingParser.parse\u001b[1;34m(self, completion)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries:\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         retries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\fix.py:59\u001b[0m, in \u001b[0;36mOutputFixingParser.parse\u001b[1;34m(self, completion)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retries \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries:\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain\\output_parsers\\datetime.py:49\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(response\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse datetime string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse datetime string: Datetime string: \"0000-12-25T00:00:00.000000Z\""
     ]
    }
   ],
   "source": [
    "# OutputFixingParser\n",
    "\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=output_parser, llm=chat)\n",
    "\n",
    "fixed_output = fixing_parser.parse(response.content)\n",
    "\n",
    "fixed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a datetime string that matches the \\n            following pattern: \"%Y-%m-%dT%H:%M:%S.%fZ\". Examples: 1185-07-01T08:41:37.938248Z, 1377-12-27T04:08:15.894211Z, 1079-02-04T05:03:29.886425Z'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixing_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fixed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2000, 12, 25, 0, 0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for chance in range(1, 10):\n",
    "    try:\n",
    "        fixed_output = fixing_parser.parse(response.content)\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "fixed_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseSchema(name='answer', description='answer to the user\"s question', type='string'),\n",
       " ResponseSchema(name='source', description='source used to answer the user\"s question, should be a website.', type='string')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "rseponse_schema = [\n",
    "    ResponseSchema(\n",
    "        name='answer', description='answer to the user\"s question'\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name='source',\n",
    "        description='source used to answer the user\"s question, should be a website.'\n",
    "    )\n",
    "]\n",
    "\n",
    "rseponse_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='answer', description='answer to the user\"s question', type='string'), ResponseSchema(name='source', description='source used to answer the user\"s question, should be a website.', type='string')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our output_parser\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(rseponse_schema)\n",
    "\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // answer to the user\"s question\\n\\t\"source\": string  // source used to answer the user\"s question, should be a website.\\n}\\n```'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What\\'s the world\\'s largest man made structure?\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // answer to the user\"s question\\n\\t\"source\": string  // source used to answer the user\"s question, should be a website.\\n}\\n```')])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_template = \"{human_message}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_message=\"What's the world's largest man made structure?\", format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The Great Wall of China',\n",
       " 'source': 'https://www.history.com/topics/great-wall-of-china'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Student:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "john = Student(name=1.0)\n",
    "john.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Student\nname\n  Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.5/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStudent\u001b[39;00m(BaseModel):\n\u001b[0;32m      4\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m----> 6\u001b[0m john \u001b[38;5;241m=\u001b[39m \u001b[43mStudent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m john\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\pydantic\\main.py:164\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    163\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m \u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Student\nname\n  Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.5/v/string_type"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Student(BaseModel):\n",
    "    name: str\n",
    "    \n",
    "john = Student(name=1)\n",
    "john.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Car(BaseModel):\n",
    "    name: str = Field(description='Name of the car')\n",
    "    model_number: str = Field(description='Model number of the car')\n",
    "    features: List[str] = Field(description='List of features of the car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of the car\", \"title\": \"Name\", \"type\": \"string\"}, \"model_number\": {\"description\": \"Model number of the car\", \"title\": \"Model Number\", \"type\": \"string\"}, \"features\": {\"description\": \"List of features of the car\", \"items\": {\"type\": \"string\"}, \"title\": \"Features\", \"type\": \"array\"}}, \"required\": [\"name\", \"model_number\", \"features\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Car)\n",
    "\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car(name='Bugatti La Voiture Noire', model_number='1103', features=['Quad-turbocharged 8.0-liter W16 engine', '1500 horsepower', 'Top speed of 261 mph', 'Handcrafted carbon fiber body', 'One-of-a-kind design'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_template = \"{human_message}\\n{format_instructions}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(human_message=\"Tell me about the most expensive car in the world\",\n",
    "                                   format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Car"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bugatti La Voiture Noire'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1103'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.model_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quad-turbocharged 8.0-liter W16 engine',\n",
       " '1500 horsepower',\n",
       " 'Top speed of 261 mph',\n",
       " 'Handcrafted carbon fiber body',\n",
       " 'One-of-a-kind design']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest update\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../openai_api_key.txt') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(BaseModel):\n",
    "    name: str = Field(description=\"Name of the car\")\n",
    "    model_number: str = Field(description=\"Model number of the car\")\n",
    "    features: List[str] = Field(description=\"List of features of the car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car(name='Bugatti La Voiture Noire', model_number='1234', features=['Ultimate luxury', 'Unique design', 'Powerful engine'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI()\n",
    "model_with_structure = model.with_structured_output(Car)\n",
    "model_with_structure.invoke('Tell me about the most expensive car in the world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ai21\n",
      "  Downloading langchain_ai21-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ai21==2.0.5 (from langchain-ai21)\n",
      "  Downloading ai21-2.0.5-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.22 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langchain-ai21) (0.1.27)\n",
      "Collecting ai21-tokenizer<0.4.0,>=0.3.9 (from ai21==2.0.5->langchain-ai21)\n",
      "  Downloading ai21_tokenizer-0.3.11-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.3 in c:\\users\\samoj\\appdata\\roaming\\python\\python39\\site-packages (from ai21==2.0.5->langchain-ai21) (0.6.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from ai21==2.0.5->langchain-ai21) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\samoj\\appdata\\roaming\\python\\python39\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (0.1.10)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\samoj\\appdata\\roaming\\python\\python39\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (2.5.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.22->langchain-ai21) (8.2.3)\n",
      "Collecting sentencepiece<0.2.0,>=0.1.96 (from ai21-tokenizer<0.4.0,>=0.3.9->ai21==2.0.5->langchain-ai21)\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (4.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\samoj\\appdata\\roaming\\python\\python39\\site-packages (from dataclasses-json<0.7.0,>=0.6.3->ai21==2.0.5->langchain-ai21) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\samoj\\appdata\\roaming\\python\\python39\\site-packages (from dataclasses-json<0.7.0,>=0.6.3->ai21==2.0.5->langchain-ai21) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.22->langchain-ai21) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->ai21==2.0.5->langchain-ai21) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->ai21==2.0.5->langchain-ai21) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\codework\\github\\langchain_training\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->ai21==2.0.5->langchain-ai21) (2024.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\samoj\\appdata\\roaming\\python\\python39\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.3->ai21==2.0.5->langchain-ai21) (1.0.0)\n",
      "Downloading langchain_ai21-0.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading ai21-2.0.5-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.1/53.1 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading ai21_tokenizer-0.3.11-py3-none-any.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.9/2.7 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.7/2.7 MB 18.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.2/2.7 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.5/2.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 10.0 MB/s eta 0:00:00\n",
      "Using cached sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "Installing collected packages: sentencepiece, ai21-tokenizer, ai21, langchain-ai21\n",
      "Successfully installed ai21-2.0.5 ai21-tokenizer-0.3.11 langchain-ai21-0.1.0 sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingApiKeyError",
     "evalue": "MissingApiKeyError API key must be supplied either globally in the ai21 namespace, or to be provided in the call args",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingApiKeyError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../openai_api_key.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 8\u001b[0m tsm \u001b[38;5;241m=\u001b[39m \u001b[43mAI21ContextualAnswers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m chain \u001b[38;5;241m=\u001b[39m tsm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     11\u001b[0m chain\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErick likes to ride bikes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho likes bikes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m })\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\pydantic\\v1\\main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1104\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\langchain_ai21\\ai21_base.py:41\u001b[0m, in \u001b[0;36mAI21Base.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     38\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout_sec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m timeout_sec\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mAI21Client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_secret_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvia\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlangchain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\ai21\\clients\\studio\\ai21_client.py:42\u001b[0m, in \u001b[0;36mAI21Client.__init__\u001b[1;34m(self, api_key, api_host, headers, timeout_sec, num_retries, via, http_client, env_config, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     41\u001b[0m ):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client \u001b[38;5;241m=\u001b[39m \u001b[43mAI21HTTPClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_host\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvia\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvia\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion \u001b[38;5;241m=\u001b[39m StudioCompletion(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat \u001b[38;5;241m=\u001b[39m StudioChat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client)\n",
      "File \u001b[1;32md:\\CodeWork\\GitHub\\langchain_training\\.venv\\lib\\site-packages\\ai21\\ai21_http_client.py:26\u001b[0m, in \u001b[0;36mAI21HTTPClient.__init__\u001b[1;34m(self, api_key, requires_api_key, api_host, api_version, headers, timeout_sec, num_retries, via, http_client)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requires_api_key \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingApiKeyError()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_host \u001b[38;5;241m=\u001b[39m api_host\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_version \u001b[38;5;241m=\u001b[39m api_version\n",
      "\u001b[1;31mMissingApiKeyError\u001b[0m: MissingApiKeyError API key must be supplied either globally in the ai21 namespace, or to be provided in the call args"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ai21 import AI21ContextualAnswers\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "with open('../openai_api_key.txt', 'r') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.read()\n",
    "\n",
    "tsm = AI21ContextualAnswers()\n",
    "chain = tsm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"context\": \"Erick likes to ride bikes\",\n",
    "    \"question\": \"Who likes bikes\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartChef(BaseModel):\n",
    "    name: str = Field(description='Name of the dish')\n",
    "    ingredients: dict = Field(description='Python dictionary of ingredients and their corresponding quantities as key and values of the python dictionary respectively.')\n",
    "    instructions: List[str] = Field(description='Python list of instructions to prepare the dish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of the dish\", \"title\": \"Name\", \"type\": \"string\"}, \"ingredients\": {\"description\": \"Python dictionary of ingredients and their corresponding quantities as key and values of the python dictionary respectively.\", \"title\": \"Ingredients\", \"type\": \"object\"}, \"instructions\": {\"description\": \"Python list of instructions to prepare the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Instructions\", \"type\": \"array\"}}, \"required\": [\"name\", \"ingredients\", \"instructions\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=SmartChef)\n",
    "\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmartChef(name='Turmeric Cumin Rice', ingredients={'rice': '2 cups', 'onion': '1 medium, chopped', 'tomatoes': '2, chopped', 'ginger garlic paste': '1 tbsp', 'turmeric': '1 tsp', 'cumin seeds': '1 tsp'}, instructions=['Rinse the rice under cold water until the water runs clear.', 'In a pan, heat some oil and add the cumin seeds. Let them splutter.', 'Add the chopped onions and sautÃ© until translucent.', 'Add the ginger garlic paste and sautÃ© for another minute.', 'Add the chopped tomatoes, turmeric, and salt. Cook until the tomatoes are soft.', 'Add the rinsed rice and sautÃ© for a couple of minutes.', 'Add 4 cups of water and bring to a boil. Reduce heat, cover, and let it simmer until the rice is cooked.', 'Fluff the rice with a fork and serve hot.'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response\n",
    "\n",
    "human_template = \"\"\"I have the following list of food items:\n",
    "\n",
    "{food_items}\n",
    "\n",
    "Suggest me a recipe only using these food items\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "prompt = chat_prompt.format_prompt(\n",
    "    food_items=\"rice, onion, tomatoes, ginger garlic paste, turmeric, cumin seeds\",\n",
    "    format_instructions=output_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "messages = prompt.to_messages()\n",
    "\n",
    "response = chat(messages=messages)\n",
    "\n",
    "output = output_parser.parse(response.content)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.SmartChef"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks\n",
    "\n",
    "# Create a Hugging face account\n",
    "# create a heroku account\n",
    "\n",
    "# Build a project\n",
    "\n",
    "# Real time text translation (import audio in gradio)\n",
    "# Text Summarization tool (topic wise summarizer)\n",
    "# Q&A Sysytem\n",
    "# Travel Planner\n",
    "# Tweet Responder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
